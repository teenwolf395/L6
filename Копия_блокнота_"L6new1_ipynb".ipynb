{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9Is2A6LAIiJao7dOxiv2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teenwolf395/L6/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22L6new1_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOukruQgA9_i"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Шаг 1: Загружаем kaggle.json\n",
        "print(\"Пожалуйста, загрузите файл kaggle.json:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Проверяем, что файл загружен\n",
        "if 'kaggle.json' not in uploaded:\n",
        "    print(\"Ошибка: файл kaggle.json не найден среди загруженных файлов\")\n",
        "else:\n",
        "    print(\"Файл kaggle.json успешно загружен\")\n",
        "\n",
        "    # Шаг 2: Настраиваем Kaggle API\n",
        "    source_path = 'kaggle.json'\n",
        "    destination_dir = os.path.expanduser('~/.kaggle')\n",
        "    destination_path = os.path.join(destination_dir, 'kaggle.json')\n",
        "\n",
        "    # Создаем директорию, если не существует\n",
        "    os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "    # Перемещаем файл\n",
        "    shutil.move(source_path, destination_path)\n",
        "\n",
        "    # Устанавливаем правильные права доступа\n",
        "    os.chmod(destination_path, 0o600)\n",
        "\n",
        "    print(\"Kaggle API настроен успешно\")\n",
        "\n",
        "    # Шаг 3: Скачиваем датасет\n",
        "    print(\"Скачиваем датасет\")\n",
        "    !kaggle datasets download -d chik0di/health-and-lifestyle-dataset\n",
        "\n",
        "    # Шаг 4: Распаковываем\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile('health-and-lifestyle-dataset.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "\n",
        "    print(\"Датасет готов к использованию!\")"
      ],
      "metadata": {
        "id": "GeoFXM78BH8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "Health = pd.DataFrame()\n",
        "try:\n",
        "    if os.path.getsize('health_lifestyle_dataset.csv') > 0:\n",
        "      Health = pd.read_csv('health_lifestyle_dataset.csv')\n",
        "      type(Health)\n",
        "      print('Файл проимпортирован\\n')\n",
        "    else:\n",
        "      print('Файл пустой')\n",
        "except OSError as e:\n",
        "    print('Файла не существует')"
      ],
      "metadata": {
        "id": "mAsETnT3BKy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Health.isnull().sum())"
      ],
      "metadata": {
        "id": "1n2HWVINBQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Health = Health.drop(columns=['id'])"
      ],
      "metadata": {
        "id": "cSMxIVbiBUf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "target_value = 0  # удаляем строки где smoker = 'Yes'\n",
        "\n",
        "# Находим индексы строк с нужным значением\n",
        "target_indices = Health[Health['smoker'] == target_value].index\n",
        "\n",
        "# Проверяем, достаточно ли строк для удаления\n",
        "if len(target_indices) >= 50000:\n",
        "    # Случайно выбираем 50000 индексов для удаления\n",
        "    indices_to_remove = np.random.choice(target_indices, size=50000, replace=False)\n",
        "\n",
        "    # Удаляем выбранные строки\n",
        "    Health_cleaned = Health.drop(indices_to_remove)\n",
        "\n",
        "    print(f\"Удалено 50000 строк с smoker = '{target_value}'\")\n",
        "    print(f\"Исходный размер датасета: {len(Health)}\")\n",
        "    print(f\"Новый размер датасета: {len(Health_cleaned)}\")\n",
        "else:\n",
        "    print(f\"Недостаточно строк для удаления. Найдено только {len(target_indices)} строк с smoker = '{target_value}'\")"
      ],
      "metadata": {
        "id": "OW0Gv542BXU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Исходный размер: {Health_cleaned.shape}\")\n",
        "# Исходный датасет\n",
        "Health_cleaned = pd.DataFrame(Health_cleaned)  # ваш датасет\n",
        "\n",
        "# Удаление 45,000 случайных строк\n",
        "n_to_remove = 45000\n",
        "indices_to_remove = np.random.choice(Health_cleaned.index, n_to_remove, replace=False)\n",
        "Health_cleaned = Health_cleaned.drop(indices_to_remove)\n",
        "\n",
        "\n",
        "print(f\"Новый размер: {Health_cleaned.shape}\")"
      ],
      "metadata": {
        "id": "yUeOLsf2rPjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ydata-profiling"
      ],
      "metadata": {
        "id": "g5rcwXM-BZ9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"размер датасета: {len(Health_cleaned)}\")"
      ],
      "metadata": {
        "id": "G3h1-mpnBczJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(Health_cleaned)\n",
        "\n",
        "# Базовая информация о колонках\n",
        "print(\"\\n1. Названия колонок:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "print(\"\\n2. Типы данных:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\n3. Форма датасета (строки, колонки):\")\n",
        "print(df.shape)\n",
        "\n",
        "# Подробная информация с помощью info()\n",
        "print(\"\\n=== Подробная информация ===\")\n",
        "df.info()\n",
        "\n",
        "# Статистика по числовым колонкам\n",
        "print(\"\\n=== Статистика по числовым колонкам ===\")\n",
        "print(df.describe())\n",
        "\n",
        "# Статистика по всем колонкам (включая категориальные)\n",
        "print(\"\\n=== Статистика по всем колонкам ===\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "# Просмотр первых строк для понимания данных\n",
        "print(\"\\n=== Первые 5 срок датасета ===\")\n",
        "print(df.head())\n",
        "\n",
        "# Проверка на пропущенные значения\n",
        "print(\"\\n=== Пропущенные значения ===\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Уникальные значения для каждой колонки\n",
        "print(\"\\n=== Уникальные значения ===\")\n",
        "for column in df.columns:\n",
        "    unique_count = df[column].nunique()\n",
        "    print(f\"{column}: {unique_count} уникальных значений\")\n",
        "    if unique_count <= 10:  # Показываем значения только если их немного\n",
        "        print(f\"   Значения: {df[column].unique()}\")\n",
        "\n",
        "# Дополнительная информация о каждой колонке\n",
        "print(\"\\n=== Детальная информация о каждой колонке ===\")\n",
        "for column in df.columns:\n",
        "    print(f\"\\n--- {column} ---\")\n",
        "    print(f\"Тип данных: {df[column].dtype}\")\n",
        "    print(f\"Количество non-null значений: {df[column].count()}\")\n",
        "    print(f\"Количество уникальных значений: {df[column].nunique()}\")\n",
        "\n",
        "    if df[column].dtype in ['int64', 'float64']:\n",
        "        print(f\"Минимальное значение: {df[column].min()}\")\n",
        "        print(f\"Максимальное значение: {df[column].max()}\")\n",
        "        print(f\"Среднее значение: {df[column].mean():.2f}\")\n",
        "\n",
        "    if df[column].dtype == 'object':\n",
        "        print(f\"Пример значений: {df[column].iloc[:3].tolist()}\")\n",
        "\n",
        "# Визуальное представление информации о данных\n",
        "print(\"\\n=== Визуализация ===\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Информация о типах данных\n",
        "type_counts = df.dtypes.value_counts()\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "type_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title('Распределение типов данных')\n",
        "plt.xlabel('Тип данных')\n",
        "plt.ylabel('Количество колонок')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "missing_values = df.isnull().sum()\n",
        "if (missing_values > 0).any():\n",
        "    missing_values[missing_values > 0].plot(kind='bar', color='lightcoral')\n",
        "    plt.title('Пропущенные значения по колонкам')\n",
        "    plt.xlabel('Колонки')\n",
        "    plt.ylabel('Количество пропусков')\n",
        "else:\n",
        "    # Если пропусков нет, показываем сообщение\n",
        "    plt.text(0.5, 0.5, 'Пропущенных значений нет!',\n",
        "             horizontalalignment='center', verticalalignment='center',\n",
        "             transform=plt.gca().transAxes, fontsize=14, color='green')\n",
        "    plt.title('Пропущенные значения по колонкам')\n",
        "    plt.xlabel('Колонки')\n",
        "    plt.ylabel('Количество пропусков')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Использование pandas-profiling для полного отчета\n",
        "\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "print(\"\\n=== Генерация полного отчета ===\")\n",
        "profile = ProfileReport(df, title=\"Полный отчет о датасете\")\n",
        "profile.to_file(\"report.html\")  # Сохраняем в файл\n",
        "\n",
        "print(\"Анализ завершен!\")"
      ],
      "metadata": {
        "id": "3f3WSAd1Bfpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка необходимых библиотек\n",
        "!pip install seaborn scipy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Настройка отображения графиков\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ],
      "metadata": {
        "id": "oBSPCnYIBnXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Статистический анализ числовых колонок\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Выбираем только числовые колонки\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "print(f\"Числовые колонки: {list(numeric_cols)}\")\n",
        "\n",
        "stats_summary = []\n",
        "for col in numeric_cols:\n",
        "    stats_summary.append({\n",
        "        'Колонка': col,\n",
        "        'Медиана': df[col].median(),\n",
        "        'СКО': df[col].std(),\n",
        "        'Асимметрия': df[col].skew(),\n",
        "        'Эксцесс': df[col].kurtosis(),\n",
        "        'Квартиль 25%': df[col].quantile(0.25),\n",
        "        'Квартиль 75%': df[col].quantile(0.75),\n",
        "        'IQR': df[col].quantile(0.75) - df[col].quantile(0.25)\n",
        "    })\n",
        "\n",
        "stats_df = pd.DataFrame(stats_summary)\n",
        "print( stats_df.round(3))"
      ],
      "metadata": {
        "id": "25Xe0_vrBofU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Анализ категориальных колонок\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "print(f\"Категориальные колонки: {list(categorical_cols)}\")\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(f\"Количество уникальных значений: {df[col].nunique()}\")\n",
        "    print(f\"Топ-5 самых частых значений:\")\n",
        "    print(df[col].value_counts().head())"
      ],
      "metadata": {
        "id": "ZSqOYsNIBro4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Распределение\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Гистограммы для числовых колонок\n",
        "if len(numeric_cols) > 0:\n",
        "    n_cols = min(3, len(numeric_cols))\n",
        "    n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
        "    axes = axes.flatten() if len(numeric_cols) > 1 else [axes]\n",
        "\n",
        "    for i, col in enumerate(numeric_cols):\n",
        "        if i < len(axes):\n",
        "            df[col].hist(bins=30, ax=axes[i], alpha=0.7, color='skyblue')\n",
        "            axes[i].set_title(f'Распределение {col}')\n",
        "            axes[i].set_xlabel(col)\n",
        "            axes[i].set_ylabel('Частота')\n",
        "\n",
        "    # Скрываем пустые subplots\n",
        "    for i in range(len(numeric_cols), len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CgJdRN8cBucB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Анализ выбрасов\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def detect_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
        "    return outliers\n",
        "\n",
        "# Определяем числовые колонки\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if len(numeric_cols) > 0:\n",
        "    numeric_cols = numeric_cols[:-1]\n",
        "\n",
        "outliers_summary = []\n",
        "for col in numeric_cols:\n",
        "    outliers = detect_outliers_iqr(df[col].dropna())\n",
        "    outlier_percent = (len(outliers) / len(df[col].dropna())) * 100\n",
        "    outliers_summary.append({\n",
        "        'Колонка': col,\n",
        "        'Выбросы': len(outliers),\n",
        "        'Процент': outlier_percent\n",
        "    })\n",
        "\n",
        "outliers_df = pd.DataFrame(outliers_summary)\n",
        "print(outliers_df)\n",
        "\n",
        "# Boxplot для визуализации выбросов\n",
        "if len(numeric_cols) > 0:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    df[numeric_cols].boxplot()\n",
        "    plt.title('Boxplot для выявления выбросов (без последней колонки)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Mn_uXzkXBxeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Корреляуионный анализ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if len(numeric_cols) > 1:\n",
        "    # Матрица корреляций\n",
        "    correlation_matrix = df[numeric_cols].corr()\n",
        "    print(\"Матрица корреляций:\")\n",
        "    print(correlation_matrix.round(3))\n",
        "\n",
        "    # Тепловая карта корреляций\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm',\n",
        "                center=0, square=True, fmt='.2f')\n",
        "    plt.title('Тепловая карта корреляций')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Поиск сильных корреляций\n",
        "    strong_correlations = []\n",
        "    for i in range(len(correlation_matrix.columns)):\n",
        "        for j in range(i+1, len(correlation_matrix.columns)):\n",
        "            corr = correlation_matrix.iloc[i, j]\n",
        "            if abs(corr) > 0.7:\n",
        "                strong_correlations.append({\n",
        "                    'Колонка 1': correlation_matrix.columns[i],\n",
        "                    'Колонка 2': correlation_matrix.columns[j],\n",
        "                    'Корреляция': corr\n",
        "                })\n",
        "\n",
        "    if strong_correlations:\n",
        "        print(\"\\nСильные корреляции (|r| > 0.7):\")\n",
        "        strong_corr_df = pd.DataFrame(strong_correlations)\n",
        "        print(strong_corr_df.round(3))\n",
        "    else:\n",
        "        print(\"\\n Сильных корреляций не обнаружено\")"
      ],
      "metadata": {
        "id": "gRsjsPPRB0cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Анализ взаимосвязей между переменными\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Scatter plot для числовых переменных\n",
        "if len(numeric_cols) >= 2:\n",
        "    # Берем первые 4 числовые колонки для scatter matrix\n",
        "    scatter_cols = numeric_cols[:4]\n",
        "    pd.plotting.scatter_matrix(df[scatter_cols], alpha=0.6, figsize=(12, 12))\n",
        "    plt.suptitle('Матрица scatter plots', y=0.95)\n",
        "    plt.show()\n",
        "\n",
        "# Анализ категориальных vs числовых переменных\n",
        "if len(categorical_cols) > 0 and len(numeric_cols) > 0:\n",
        "    cat_col = categorical_cols[0]\n",
        "    num_col = numeric_cols[0]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.boxplot(data=df, x=cat_col, y=num_col)\n",
        "    plt.title(f'Распределение {num_col} по категориям {cat_col}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XSQBxqQCB3Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Итоговый отчет EDA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"Основные выводы:\")\n",
        "print(f\"- Общий размер датасета: {df.shape[0]} строк, {df.shape[1]} колонок\")\n",
        "print(f\"- Числовых колонок: {len(numeric_cols)}\")\n",
        "print(f\"- Категориальных колонок: {len(categorical_cols)}\")\n",
        "print(f\"- Пропущенных значений: {df.isnull().sum().sum()}\")\n",
        "\n",
        "if len(numeric_cols) > 0:\n",
        "    high_skew = stats_df[abs(stats_df['Асимметрия']) > 1]['Колонка'].tolist()\n",
        "    if high_skew:\n",
        "        print(f\"- Колонки с высокой асимметрией: {high_skew}\")\n",
        "\n",
        "if 'outliers_df' in locals():\n",
        "    high_outliers = outliers_df[outliers_df['Процент'] > 5]['Колонка'].tolist()\n",
        "    if high_outliers:\n",
        "        print(f\"- Колонки с большим количеством выбросов (>5%): {high_outliers}\")\n",
        "print(\"EDA анализ завершен!\")"
      ],
      "metadata": {
        "id": "wiVjCmaHB56Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Health_cleaned1=pd.DataFrame(Health_cleaned)\n",
        "if 'gender' in Health_cleaned1.columns:\n",
        "    print(f\"Уникальные значения до преобразования: {Health_cleaned['gender'].unique()}\")\n",
        "\n",
        "    # Кодируем текстовые значения M/F в числа\n",
        "    gender_encoder = LabelEncoder()\n",
        "    Health_cleaned1['gender'] = gender_encoder.fit_transform(Health_cleaned['gender'])\n",
        "\n",
        "    # Создаем mapping для обратного преобразования\n",
        "    gender_mapping = {i: label for i, label in enumerate(gender_encoder.classes_)}\n",
        "    print(f\"Преобразование: {gender_mapping}\")\n",
        "\n",
        "    print(f\"Уникальные значения после преобразования: {sorted(Health_cleaned1['gender'].unique())}\")\n",
        "    print(f\"Распределение после: {Health_cleaned1['gender'].value_counts().to_dict()}\")\n",
        "else:\n",
        "    print(f\"Колонка GENDER не найдена в датасете\")"
      ],
      "metadata": {
        "id": "-llnmedHwZDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Health_cleaned1.info()\n",
        "print(\"\\n=== ДЕТАЛЬНАЯ ИНФОРМАЦИЯ ПО КАЖДОЙ КОЛОНКЕ ===\")\n",
        "for column in Health_cleaned1.columns:\n",
        "    print(f\"\\n--- {column} ---\")\n",
        "    print(f\"Тип данных: {Health_cleaned1[column].dtype}\")\n",
        "    print(f\"Количество non-null значений: {Health_cleaned1[column].count()}\")\n",
        "    print(f\"Количество уникальных значений: {Health_cleaned1[column].nunique()}\")\n",
        "\n",
        "    if Health_cleaned1[column].dtype in ['int64', 'float64']:\n",
        "        print(f\"Минимальное значение: {Health_cleaned1[column].min()}\")\n",
        "        print(f\"Максимальное значение: {Health_cleaned1[column].max()}\")\n",
        "        print(f\"Среднее значение: {Health_cleaned1[column].mean():.2f}\")\n",
        "\n",
        "    if Health_cleaned1[column].dtype == 'object':\n",
        "        print(f\"Пример значений: {Health_cleaned1[column].iloc[:3].tolist()}\")"
      ],
      "metadata": {
        "id": "xJgcD6j4v5Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, Birch, SpectralClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.DataFrame(Health_cleaned1)\n",
        "\n",
        "print(\"Первые 5 строк датасета:\")\n",
        "print(df.head())\n",
        "print(f\"\\nРазмер датасета: {df.shape}\")\n",
        "\n",
        "# Предобработка данных\n",
        "print(\"\\n=== Предобработка данных ===\")\n",
        "\n",
        "# Выбор признаков для кластеризации\n",
        "features = ['age', 'gender','bmi', 'daily_steps', 'sleep_hours', 'water_intake_l', 'calories_consumed', 'resting_hr', 'systolic_bp', 'diastolic_bp', 'cholesterol',  'smoker', 'alcohol', 'family_history']\n",
        "\n",
        "X = df[features]\n",
        "\n",
        "# Масштабирование данных\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"Размерность данных после масштабирования: {X_scaled.shape}\")\n",
        "\n",
        "# Определение оптимального числа кластеров\n",
        "print(\"\\n=== Определение оптимального числа кластеров ===\")\n",
        "\n",
        "inertia = []\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "    if len(np.unique(labels)) > 1:\n",
        "        score = silhouette_score(X_scaled, labels)\n",
        "        silhouette_scores.append(score)\n",
        "    else:\n",
        "        silhouette_scores.append(0)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(k_range, inertia, 'bo-')\n",
        "plt.xlabel('Количество кластеров')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Метод локтя')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(k_range, silhouette_scores, 'ro-')\n",
        "plt.xlabel('Количество кластеров')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Выбираем оптимальное число кластеров\n",
        "optimal_clusters = k_range[np.argmax(silhouette_scores)]\n",
        "print(f\"Выбрано оптимальное число кластеров: {optimal_clusters}\")\n",
        "\n",
        "# K-MEANS CLUSTERING\n",
        "print(\"\\n=== K-MEANS CLUSTERING ===\")\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42, n_init=10)\n",
        "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
        "df['kmeans_cluster'] = kmeans_labels\n",
        "kmeans_score = silhouette_score(X_scaled, kmeans_labels)\n",
        "print(f\"K-Means Silhouette Score: {kmeans_score:.4f}\")\n",
        "\n",
        "# GAUSSIAN MIXTURE MODELS\n",
        "print(\"\\n=== GAUSSIAN MIXTURE MODELS ===\")\n",
        "gmm = GaussianMixture(n_components=optimal_clusters, random_state=42)\n",
        "gmm_labels = gmm.fit_predict(X_scaled)\n",
        "df['gmm_cluster'] = gmm_labels\n",
        "gmm_score = silhouette_score(X_scaled, gmm_labels)\n",
        "print(f\"GMM Silhouette Score: {gmm_score:.4f}\")\n",
        "\n",
        "# AGGLOMERATIVE CLUSTERING\n",
        "print(\"\\n=== AGGLOMERATIVE CLUSTERING ===\")\n",
        "agglo = AgglomerativeClustering(n_clusters=optimal_clusters)\n",
        "agglo_labels = agglo.fit_predict(X_scaled)\n",
        "df['agglo_cluster'] = agglo_labels\n",
        "agglo_score = silhouette_score(X_scaled, agglo_labels)\n",
        "print(f\"Agglomerative Silhouette Score: {agglo_score:.4f}\")\n",
        "\n",
        "# BIRCH CLUSTERING\n",
        "print(\"\\n=== BIRCH CLUSTERING ===\")\n",
        "birch = Birch(n_clusters=optimal_clusters, threshold=0.5, branching_factor=50)\n",
        "birch_labels = birch.fit_predict(X_scaled)\n",
        "df['birch_cluster'] = birch_labels\n",
        "birch_score = silhouette_score(X_scaled, birch_labels)\n",
        "print(f\"BIRCH Silhouette Score: {birch_score:.4f}\")\n",
        "\n",
        "# SPECTRAL CLUSTERING\n",
        "print(\"\\n=== SPECTRAL CLUSTERING ===\")\n",
        "spectral = SpectralClustering(n_clusters=optimal_clusters, random_state=42, affinity='rbf')\n",
        "spectral_labels = spectral.fit_predict(X_scaled)\n",
        "df['spectral_cluster'] = spectral_labels\n",
        "spectral_score = silhouette_score(X_scaled, spectral_labels)\n",
        "print(f\"Spectral Clustering Silhouette Score: {spectral_score:.4f}\")\n",
        "\n",
        "# Сводка результатов отдельных методов\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Сводим результаты отдельных методов\")\n",
        "print(\"=\"*60)\n",
        "methods_scores = {\n",
        "    'K-Means': kmeans_score,\n",
        "    'GMM': gmm_score,\n",
        "    'Agglomerative': agglo_score,\n",
        "    'BIRCH': birch_score,\n",
        "    'Spectral': spectral_score\n",
        "}\n",
        "\n",
        "for method, score in methods_scores.items():\n",
        "    print(f\"{method}: {score:.4f}\")\n",
        "\n",
        "best_individual_method = max(methods_scores, key=methods_scores.get)\n",
        "print(f\"\\nЛучший индивидуальный метод: {best_individual_method} (Score: {methods_scores[best_individual_method]:.4f})\")\n",
        "\n",
        "# АНСАМБЛЬ МОДЕЛЕЙ - Weighted Voting\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Ансамбль методов - Weighted Voting\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Создаем матрицу предсказаний всех методов\n",
        "cluster_predictions = np.column_stack([\n",
        "    kmeans_labels,\n",
        "    gmm_labels,\n",
        "    agglo_labels,\n",
        "    birch_labels,\n",
        "    spectral_labels\n",
        "])\n",
        "\n",
        "# Weighted Voting (взвешенное голосование)\n",
        "weights = np.array([kmeans_score, gmm_score, agglo_score, birch_score, spectral_score])\n",
        "weights = weights / weights.sum()  # Нормализуем веса\n",
        "\n",
        "print(\"Веса методов в ансамбле:\")\n",
        "for method, weight in zip(methods_scores.keys(), weights):\n",
        "    print(f\"  {method}: {weight:.3f}\")\n",
        "\n",
        "# Взвешенное голосование\n",
        "weighted_predictions = np.zeros((len(X_scaled), optimal_clusters))\n",
        "for i in range(cluster_predictions.shape[1]):\n",
        "    for j in range(optimal_clusters):\n",
        "        mask = (cluster_predictions[:, i] == j)\n",
        "        weighted_predictions[mask, j] += weights[i]\n",
        "\n",
        "ensemble_weighted = np.argmax(weighted_predictions, axis=1)\n",
        "df['ensemble_weighted'] = ensemble_weighted\n",
        "ensemble_weighted_score = silhouette_score(X_scaled, ensemble_weighted)\n",
        "print(f\"\\nWeighted Voting Silhouette Score: {ensemble_weighted_score:.4f}\")\n",
        "\n",
        "# Сравнение всех методов\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Сравнение методов\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_methods_scores = {\n",
        "    'K-Means': kmeans_score,\n",
        "    'GMM': gmm_score,\n",
        "    'Agglomerative': agglo_score,\n",
        "    'BIRCH': birch_score,\n",
        "    'Spectral': spectral_score,\n",
        "    'Ensemble Weighted': ensemble_weighted_score\n",
        "}\n",
        "\n",
        "for method, score in all_methods_scores.items():\n",
        "    print(f\"{method}: {score:.4f}\")\n",
        "\n",
        "best_overall_method = max(all_methods_scores, key=all_methods_scores.get)\n",
        "print(f\"\\n Лучший метод из всех: {best_overall_method} (Score: {all_methods_scores[best_overall_method]:.4f})\")\n",
        "\n",
        "# Визуализация результатов\n",
        "print(\"\\n=== Визуализация результатов ===\")\n",
        "\n",
        "# PCA для визуализации\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"Объясненная дисперсия PCA: {pca.explained_variance_ratio_.sum():.3f}\")\n",
        "\n",
        "# Визуализация всех методов\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "methods_for_viz = [\n",
        "    ('K-Means', kmeans_labels, kmeans_score),\n",
        "    ('GMM', gmm_labels, gmm_score),\n",
        "    ('Agglomerative', agglo_labels, agglo_score),\n",
        "    ('BIRCH', birch_labels, birch_score),\n",
        "    ('Spectral', spectral_labels, spectral_score),\n",
        "    ('Ensemble Weighted', ensemble_weighted, ensemble_weighted_score)\n",
        "]\n",
        "\n",
        "for i, (method, labels, score) in enumerate(methods_for_viz):\n",
        "    scatter = axes[i].scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='tab10', alpha=0.7, s=30)\n",
        "    axes[i].set_title(f'{method}\\nSilhouette: {score:.4f}', fontsize=10)\n",
        "    axes[i].set_xlabel('PC1')\n",
        "    axes[i].set_ylabel('PC2')\n",
        "    plt.colorbar(scatter, ax=axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Анализ лучшего метода\n",
        "print(\"\\n=== Детальный анализ лучшего метода ===\")\n",
        "\n",
        "# Определяем, какой метод лучший и получаем его метки\n",
        "if best_overall_method == 'Ensemble Weighted':\n",
        "    best_labels = ensemble_weighted\n",
        "    method_type = \"ансамблевый метод Weighted Voting\"\n",
        "else:\n",
        "    # Сопоставляем название метода с соответствующими метками\n",
        "    method_mapping = {\n",
        "        'K-Means': kmeans_labels,\n",
        "        'GMM': gmm_labels,\n",
        "        'Agglomerative': agglo_labels,\n",
        "        'BIRCH': birch_labels,\n",
        "        'Spectral': spectral_labels\n",
        "    }\n",
        "    best_labels = method_mapping[best_overall_method]\n",
        "    method_type = f\"индивидуальный метод {best_overall_method}\"\n",
        "\n",
        "print(f\"Используется {method_type}\")\n",
        "\n",
        "# Анализ кластеров лучшего метода\n",
        "print(f\"\\n Анализ кластеров лучшего метода ({best_overall_method}):\")\n",
        "\n",
        "for cluster in range(optimal_clusters):\n",
        "    cluster_mask = (best_labels == cluster)\n",
        "    cluster_data = df[cluster_mask]\n",
        "    cluster_size = len(cluster_data)\n",
        "\n",
        "    print(f\"\\n--- КЛластер {cluster} (размер: {cluster_size}, {cluster_size/len(df)*100:.1f}%) ---\")\n",
        "\n",
        "    # Вычисляем средние значения для кластера\n",
        "    cluster_means = cluster_data[features].mean()\n",
        "    global_means = df[features].mean()\n",
        "\n",
        "    # Находим наиболее отличительные признаки\n",
        "    differences = (cluster_means - global_means)\n",
        "    top_positive = differences.nlargest(3)\n",
        "    top_negative = differences.nsmallest(3)\n",
        "\n",
        "    print(\" Повышенные показатели:\")\n",
        "    for feature, diff in top_positive.items():\n",
        "        if diff > 0:\n",
        "            percent_diff = (diff / global_means[feature]) * 100\n",
        "            print(f\"  {feature}: +{diff:.2f} ({percent_diff:+.1f}%)\")\n",
        "\n",
        "    print(\" Пониженные показатели:\")\n",
        "    for feature, diff in top_negative.items():\n",
        "        if diff < 0:\n",
        "            percent_diff = (diff / global_means[feature]) * 100\n",
        "            print(f\"  {feature}: {diff:.2f} ({percent_diff:+.1f}%)\")\n",
        "\n",
        "    risk_percent = cluster_data['disease_risk'].mean() * 100\n",
        "    print(f\" Риск заболевания: {risk_percent:.1f}%\")\n",
        "\n",
        "# Визуализация профилей кластеров лучшего метода\n",
        "print(\"\\n=== Визуализация профилей кластеров ===\")\n",
        "\n",
        "# Создаем временный DataFrame для визуализации\n",
        "viz_df = df.copy()\n",
        "viz_df['best_cluster'] = best_labels\n",
        "\n",
        "# Группируем по кластерам для получения средних значений\n",
        "cluster_profiles = viz_df.groupby('best_cluster')[features + ['disease_risk']].mean()\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Размеры кластеров\n",
        "plt.subplot(2, 2, 1)\n",
        "cluster_sizes = viz_df['best_cluster'].value_counts().sort_index()\n",
        "plt.pie(cluster_sizes.values, labels=[f'Cluster {i}' for i in cluster_sizes.index],\n",
        "        autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff','#99ff99','#ffcc99'])\n",
        "plt.title('Распределение по кластерам')\n",
        "\n",
        "#  Disease risk по кластерам\n",
        "plt.subplot(2, 2, 2)\n",
        "risk_by_cluster = viz_df.groupby('best_cluster')['disease_risk'].mean()\n",
        "colors = ['green', 'orange', 'red', 'purple']\n",
        "plt.bar(risk_by_cluster.index, risk_by_cluster.values * 100,\n",
        "        color=colors[:optimal_clusters], alpha=0.7)\n",
        "plt.xlabel('Кластер')\n",
        "plt.ylabel('Процент с disease_risk (%)')\n",
        "plt.title('Распределение disease_risk по кластерам')\n",
        "for i, v in enumerate(risk_by_cluster.values):\n",
        "    plt.text(i, v * 100 + 1, f'{v*100:.1f}%', ha='center', fontweight='bold')\n",
        "\n",
        "#  Сравнение ключевых метрик здоровья\n",
        "plt.subplot(2, 2, 3)\n",
        "key_metrics = ['bmi', 'daily_steps', 'sleep_hours', 'cholesterol']\n",
        "cluster_means = viz_df.groupby('best_cluster')[key_metrics].mean()\n",
        "\n",
        "x = np.arange(len(key_metrics))\n",
        "width = 0.15\n",
        "\n",
        "for i, cluster in enumerate(cluster_profiles.index):\n",
        "    values = [cluster_means.loc[cluster, metric] for metric in key_metrics]\n",
        "    plt.bar(x + i*width, values, width, label=f'Cluster {cluster}', alpha=0.8)\n",
        "\n",
        "plt.xlabel('Метрики здоровья')\n",
        "plt.ylabel('Средние значения')\n",
        "plt.title('Сравнение ключевых метрик по кластерам')\n",
        "plt.xticks(x + width * (optimal_clusters-1)/2, key_metrics, rotation=45)\n",
        "plt.legend()\n",
        "\n",
        "# Сравнение методов кластеризации\n",
        "plt.subplot(2, 2, 4)\n",
        "methods = list(all_methods_scores.keys())\n",
        "scores = list(all_methods_scores.values())\n",
        "colors = ['blue' if method != best_overall_method else 'red' for method in methods]\n",
        "plt.bar(range(len(methods)), scores, color=colors, alpha=0.7)\n",
        "plt.title('Сравнение методов кластеризации')\n",
        "plt.xticks(range(len(methods)), methods, rotation=45)\n",
        "plt.ylabel('Silhouette Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Финал\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Итого\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"Размер датасета: {df.shape}\")\n",
        "print(f\"Оптимальное число кластеров: {optimal_clusters}\")\n",
        "print(f\"Лучший метод: {best_overall_method}\")\n",
        "print(f\"Качество кластеризации (Silhouette): {all_methods_scores[best_overall_method]:.4f}\")\n",
        "\n",
        "print(\"\\n Использованные методы кластеризации:\")\n",
        "print(\"   - K-Means - centroid-based clustering\")\n",
        "print(\"   - Gaussian Mixture Models - probabilistic clustering\")\n",
        "print(\"   - Agglomerative Clustering - hierarchical clustering\")\n",
        "print(\"   - BIRCH - hierarchical clustering для больших данных\")\n",
        "print(\"   - Spectral Clustering - graph-based clustering\")\n",
        "print(\"   - Ensemble Weighted Voting - взвешенное голосование\")\n",
        "\n",
        "print(f\"\\n Результат ансамбля:\")\n",
        "print(f\"   - Weighted Voting: {ensemble_weighted_score:.4f}\")\n",
        "\n",
        "print(f\"\\nВывод: лучшая сегментация достигнута методом: {best_overall_method}\")"
      ],
      "metadata": {
        "id": "BbkassBU0-Iu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}